---
title: "Modelling"
format: html
editor: visual
execute: 
  cache: true
editor_options: 
  chunk_output_type: console
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

## Reading Data

Import the libraries

```{r}
library(tidyverse)
library(ggplot2)
library(tidymodels)
library(rpart.plot)
```

```{r}
health_data <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
head(health_data)

```

```{r}
health_data <- health_data |>
  mutate(HighBP = factor(HighBP, levels = c(0,1), labels = c("No", "Yes")),
         HighChol = factor(HighChol, levels = c(0,1), labels = c("No", "Yes")),
         CholCheck = factor(CholCheck, levels = c(0,1), labels = c("No", "Yes")),
         Smoker = factor(Smoker, levels = c(0,1), labels = c("No", "Yes")),
         Stroke = factor(Stroke, levels = c(0,1), labels = c("No", "Yes")),
         HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1), labels = c("No","Yes")),
         PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c("No", "Yes")),
         Fruits = factor(Fruits, levels = c(0,1), labels = c("No", "Yes")),
         Veggies = factor(Veggies, levels = c(0,1), labels = c("No", "Yes")),
         HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c("No", "Yes")),
         AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c("No", "Yes")),
         NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c("No", "Yes")),
         GenHlth = factor(GenHlth, levels = c(1:5), labels = c("Excellent", "Very Good", "Good", "Fair", "Poor")),
         DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c("No", "Yes")),
         Sex = factor(Sex, levels = c(0,1), labels = c("Female", "Male")),
         Age = factor(Age, levels = c(1:13), labels = c("18-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", "65-69", "70-74", "75-79", "80+")),
         Education = factor(Education, levels = c(1:6), labels = c("KG or No School", "Elementary", "Middle school", "High school", "College","Professional Degree")),
         Income = factor(Income, levels = c(1:8), labels = c("<10K", "$10k-$15k", "$15k-$20k", "$20k-$25k", "$25k-$35k", "$35k-$50k", "$50k-$75k", "$75k+"))
         )

health_data
```

```         
```

-   Make a model for diabetes data. Split the data into 70(training) and 30(testing) percent.

-   On the training set, create a 5 fold CV split

```{r}
set.seed(37)
health_data <- health_data |> mutate(Diabetes_binary = factor(Diabetes_binary))
diabetes_split <- initial_split(health_data, prop = 0.7, strata = Diabetes_binary)
diabetes_train <- training(diabetes_split)
diabetes_test <- testing(diabetes_split)

diabetes_CV_folds <- vfold_cv(diabetes_train, 5)
```

-   \### Fitting Logistic Regression Models

-   First of all i have to set up our recipes for the data, standardizing the BMI numeric variable

-   for the 1st recipe:

-   

-   Model 1: BMI and Smoker

-   Model 2: BMI, Smoker, HighBP, HearthDiseaserorAttack, PhysActivity, Sex

-   Model 3: All the predictors

```{r}
# LR1_receipe <- recipe(Diabetes_binary ~  BMI + Smoker,
#                       data = health_data) |>
#   step_normalize(BMI)
```

```{r}
LR2_recipe <- recipe(Diabetes_binary ~ BMI + Smoker + HighBP + HeartDiseaseorAttack + PhysActivity + Sex,
                     data = health_data) |>
  step_normalize(all_numeric(), -Diabetes_binary)
```

```{r}
# LR3_recipe <- recipe(Diabetes_binary ~ ., data = health_data) |>
#   step_normalize(all_numeric(), -Diabetes_binary)

```

```{r}
LR2_recipe |>
  prep(diabetes_train) |>
  bake(diabetes_train) |>
  colnames()
```

```{r}
# LR3_recipe |>
#   prep(diabetes_train) |>
#   bake(diabetes_train) |>
#   colnames()
```

### Classification Tree

### Decision Tree

Model Specification

```{r}
tree_mod <- decision_tree(tree_depth = tune(),
                          min_n = 20,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")
```

Create our Workflow

```{r}
tree_wkf <- workflow() |>
  add_recipe(LR2_recipe) |>
  add_model(tree_mod)

```

Fit the model with tune_grid() and grid_regular()

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = c(10,5))
```

```{r}
tree_fits <- tree_wkf |>
  tune_grid(resamples = diabetes_CV_folds,
            grid = tree_grid,
            metrics = metric_set(accuracy, mn_log_loss)
  )

tree_fits
```

Let see which is the best accuracy

```{r}
best_tree <- select_best(tree_fits, metric = "mn_log_loss")
```

Finalize the workflow and fit the model

```{r}
final_tree <- finalize_workflow(tree_wkf, best_tree) |>
  fit(data = diabetes_train)
```

Evaluate the model on the test set
# TRy



```{r}
tree_pred <- predict(final_tree, diabetes_test, type = "prob") |>
  bind_cols(diabetes_test |>
              select(Diabetes_binary))
```

log-loss on test data

```{r}
print(tree_pred)
tree_log_loss <- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1)
print(tree_log_loss)


```
# Try




## Fitting Random Forest

```{r}
rf_spec <- rand_forest(mtry = tune(),
                       trees = 1000, 
                       min_n = tune()) |>
  set_engine("ranger") |>
  set_mode("classification")
```

Create our workflow

```{r}
rf_wkf <- workflow() |>
  add_recipe(LR2_recipe) |>
  add_model(rf_spec)
```

fit model with tune_grid() and tune_regular()

```{r}
rf_fit <- rf_wkf |>
  tune_grid(resamples = diabetes_CV_folds,
            grid = 12,
            metrics = metric_set(accuracy, mn_log_loss))
```

Collect and view metrics

```{r}
# rf_fit |>
#   collect_metrics() |>
#   filter(.metric == "mn_log_loss") |>
#   arrange(mean)

#print(rf_metrics)
```

Let's see which tuning parameters is best

```{r}
rf_best_params <- select_best(rf_fit, metric = "mn_log_loss")
rf_best_params
```

Finalize the workflow with the best parameters

```{r}
rf_final_wkf <- rf_wkf |>
  finalize_workflow(rf_best_params)
```

Fit the finalize model and evaluate on the test set

```{r}
rf_final_fit <- rf_final_wkf |>
  last_fit(diabetes_split, metrics = metric_set(accuracy, mn_log_loss))
```

Collect metrics for the final model

```{r}
rf_final_metrics <- rf_final_fit |>
  collect_metrics()

rf_final_metrics
```

### 

-   Decision Tree Test set performance

```{r}
# Get predicted probabilities
tree_final_predictions <- final_tree |>
   predict(diabetes_test, type = "prob") |>
   bind_cols(diabetes_test |> select(Diabetes_binary))

# Convert predicted probabilities to class labels (threshold at 0.5)
 tree_final_predictions <- tree_final_predictions |>
   mutate(.pred_class = ifelse(.pred_1 > 0.5, "1", "0"))

# Convert the class labels into factors for accuracy calculation
 tree_final_predictions <- tree_final_predictions |>
   mutate(.pred_class = factor(.pred_class, levels = c("0", "1")))

# Now calculate metrics
 tree_final_metrics <- yardstick::metrics(
   tree_final_predictions,   truth = Diabetes_binary,
   estimate = .pred_class

)

# View metrics
tree_final_metrics
```

```{r}
# # Evaluation of Decision Tree
# tree_pred <- predict(final_tree, diabetes_test, type = "prob") |>
#   bind_cols(diabetes_test %>% select(Diabetes_binary))
# 
#tree_log_loss <- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1)
# 
# # Evaluation of Random Forest
# rf_pred <- predict(rf_final_fit, diabetes_test, type = "prob") |>
#   bind_cols(diabetes_test %>% select(Diabetes_binary))
# 
# # Log loss for Random Forest
# rf_log_loss <- mn_log_loss(rf_pred, truth = Diabetes_binary, .pred_1)
# 

```


```{r}

# Calculate Log-Loss for Decision Tree
tree_log_loss <- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1)

# Extract the finalized workflow from last_fit() 
rf_workflow_extracted <- extract_workflow(rf_final_fit)

# Predict probabilities on the test set
rf_pred <- predict(rf_workflow_extracted, diabetes_test, type = "prob") |>
  bind_cols(diabetes_test %>% select(Diabetes_binary))

# Calculate Log-Loss for the Random Forest Model
rf_log_loss <- mn_log_loss(rf_pred, truth = Diabetes_binary, .pred_1)

# Convert predicted probabilities to class labels for accuracy evaluation
rf_pred <- rf_pred |>
  mutate(.pred_class = ifelse(.pred_1 > 0.5, "1", "0")) |>
  mutate(.pred_class = factor(.pred_class, levels = c("0", "1")))

# Evaluate metrics (accuracy, etc.)
rf_metrics <- rf_pred |>
  yardstick::metrics(truth = Diabetes_binary, estimate = .pred_class)

# Print metrics
print(rf_metrics)


```

```{r} 
# Compare models}
# model_comparison <- tibble(
#   Model = c("Decision Tree", "Random Forest"),
#   Log_Loss = c(tree_log_loss, rf_log_loss)
# )
# 
# print(model_comparison)

print(tree_log_loss)
print(rf_log_loss)
```



-   Random Forest Test Set performance

```{r}
rf_final_metrics <- rf_final_fit |>
  collect_metrics()

rf_final_metrics
```

### Compare Performance

```{r}
# Combine Metrics into a DataFrame for Comparison
model_comparison <- tibble(
  Model = c("Decision Tree", "Random Forest"),
  Accuracy = c(tree_final_metrics |> filter(.metric == "accuracy") |> pull(.estimate),
               rf_final_metrics |> filter(.metric == "accuracy") |> pull(.estimate)),
  Log_Loss = c(tree_final_metrics |> filter(.metric =="mn_log_loss") |> pull(.estimate),
               rf_final_metrics |> filter(.metric =="mn_log_loss") |> pull(.estimate))
)

print(model_comparison)

```

```{r}
# Declare winner based on log-loss
# Calculate log-loss
tree_log_loss <- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1) %>% pull(.estimate)
rf_log_loss <- mn_log_loss(rf_pred, truth = Diabetes_binary, .pred_1) %>% pull(.estimate)
print(tree_log_loss)
print(rf_log_loss)
# Declare winner
if (tree_log_loss < rf_log_loss) {
  winner <- "Decision Tree"
} else {
  winner <- "Random Forest"
}

# Print the winner
cat("The best model is:", winner)

```

Plot the variable importance

```{r}
# bag_final_model <- extract_fit_engine(rf_final_fit)
# bag_final_model$imp |>
#   mutate(term = factor(term, levels = term)) |> 
#   ggplot(aes(x = term, y = value)) + geom_bar(stat ="identity") +
#   coord_flip()
```

### Save the file for api

```{r}
# # save the training data set
# saveRDS(diabetes_train, file = "data/diabetes_train.rds")
# 
# # save the random forest tree model
# saveRDS(rf_final_fit, file = "data/final_rf_model.rds")
# 
# #save the comparison metrics
# saveRDS(model_comparison, file = "data/model_comparison.rds")
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
