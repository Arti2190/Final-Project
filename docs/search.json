[
  {
    "objectID": "EDA_p.html",
    "href": "EDA_p.html",
    "title": "EDA",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "EDA_p.html#quarto",
    "href": "EDA_p.html#quarto",
    "title": "EDA",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "EDA_p.html#running-code",
    "href": "EDA_p.html#running-code",
    "title": "EDA",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "EDA_p.html#introduction-section",
    "href": "EDA_p.html#introduction-section",
    "title": "EDA",
    "section": "Introduction Section",
    "text": "Introduction Section\n\nData Description\nThe data set is for Diabetes Health Indicators, which contains health-related indicators collected from individuals. Our main goal is to predict the response variable Diabetes_binary, which indicated the presence(1) or absence(0) of diabetes. There are total 23 variables. Most variables are categorical, and some are encoded as integers or binary indicators. These variables will be converted into factors with meaningful level names.\nThis is a classification problem because we have to find whether the patient has diabetes or not."
  },
  {
    "objectID": "EDA_p.html#goal-",
    "href": "EDA_p.html#goal-",
    "title": "EDA",
    "section": "Goal:-",
    "text": "Goal:-\nMain goal is to predict whether a person has diabetes based on health indicators.\n\nReading Data\nImport the libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\n\n\nhealth_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(health_data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\n\n\nData preparation"
  },
  {
    "objectID": "EDA_p.html#eda",
    "href": "EDA_p.html#eda",
    "title": "EDA",
    "section": "EDA",
    "text": "EDA\n\nUnderstand the distribution and relationship between variables\nIdentify factors that influence diabetes status\nPrepare the dataset for modeling by identifying necessary transformations or imputations\n\nChecking the Data\n\nhealth_data |&gt;\n  is.na() |&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nNo missing values. Check the column type and values\n\nattributes(health_data)$spec\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\nAll columns seems reasonable.\nbriefly summarize each column to see if there is any weird values\n\nsummary(health_data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nIn the health data it looks like except BMI all the columns are categorical data so we have to convert all the columns into factor\n\nhealth_data &lt;- health_data |&gt;\n  mutate(HighBP = factor(HighBP, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         HighChol = factor(HighChol, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         CholCheck = factor(CholCheck, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Smoker = factor(Smoker, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Stroke = factor(Stroke, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1), labels = c(\"No\",\"Yes\")),\n         PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Fruits = factor(Fruits, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Veggies = factor(Veggies, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n         AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         GenHlth = factor(GenHlth, levels = c(1:5), labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n         DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Sex = factor(Sex, levels = c(0,1), labels = c(\"Female\", \"Male\")),\n         Age = factor(Age, levels = c(1:13), labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\")),\n         Education = factor(Education, levels = c(1:6), labels = c(\"KG or No School\", \"Elementary\", \"Middle school\", \"High school\", \"College\",\"Professional Degree\")),\n         Income = factor(Income, levels = c(1:8), labels = c(\"&lt;10K\", \"$10k-$15k\", \"$15k-$20k\", \"$20k-$25k\", \"$25k-$35k\", \"$35k-$50k\", \"$50k-$75k\", \"$75k+\"))\n         )\n\nhealth_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1               0 Yes    Yes      Yes          40 Yes    No    \n 2               0 No     No       No           25 Yes    No    \n 3               0 Yes    Yes      Yes          28 No     No    \n 4               0 Yes    No       Yes          27 No     No    \n 5               0 Yes    Yes      Yes          24 No     No    \n 6               0 Yes    Yes      Yes          25 Yes    No    \n 7               0 Yes    No       Yes          30 Yes    No    \n 8               0 Yes    Yes      Yes          25 Yes    No    \n 9               1 Yes    Yes      Yes          30 Yes    No    \n10               0 No     No       Yes          24 No     No    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n\n\nVerify the unique values for each column for the factor column only\n\n\n# Check unique values for categorical variables\n#sapply(health_data, function(x) if (is.factor(x)) levels(x) else NULL)\nfactor_col &lt;- health_data |&gt;\n  select(where(is.factor))\n\nlapply(factor_col, levels)\n\n$HighBP\n[1] \"No\"  \"Yes\"\n\n$HighChol\n[1] \"No\"  \"Yes\"\n\n$CholCheck\n[1] \"No\"  \"Yes\"\n\n$Smoker\n[1] \"No\"  \"Yes\"\n\n$Stroke\n[1] \"No\"  \"Yes\"\n\n$HeartDiseaseorAttack\n[1] \"No\"  \"Yes\"\n\n$PhysActivity\n[1] \"No\"  \"Yes\"\n\n$Fruits\n[1] \"No\"  \"Yes\"\n\n$Veggies\n[1] \"No\"  \"Yes\"\n\n$HvyAlcoholConsump\n[1] \"No\"  \"Yes\"\n\n$AnyHealthcare\n[1] \"No\"  \"Yes\"\n\n$NoDocbcCost\n[1] \"No\"  \"Yes\"\n\n$GenHlth\n[1] \"Excellent\" \"Very Good\" \"Good\"      \"Fair\"      \"Poor\"     \n\n$DiffWalk\n[1] \"No\"  \"Yes\"\n\n$Sex\n[1] \"Female\" \"Male\"  \n\n$Age\n [1] \"18-24\" \"25-29\" \"30-34\" \"35-39\" \"40-44\" \"45-49\" \"50-54\" \"55-59\" \"60-64\"\n[10] \"65-69\" \"70-74\" \"75-79\" \"80+\"  \n\n$Education\n[1] \"KG or No School\"     \"Elementary\"          \"Middle school\"      \n[4] \"High school\"         \"College\"             \"Professional Degree\"\n\n$Income\n[1] \"&lt;10K\"      \"$10k-$15k\" \"$15k-$20k\" \"$20k-$25k\" \"$25k-$35k\" \"$35k-$50k\"\n[7] \"$50k-$75k\" \"$75k+\"    \n\n\n\nFind the numerical summary by using contingency table\n\n\n# freq_table &lt;- sapply(health_data, function(x) if(is.factor(x)) table(x) else NULL)\n# freq_table \n\nfactor_cont_table &lt;- lapply(factor_col, table)\nfactor_cont_table\n\n$HighBP\n\n    No    Yes \n144851 108829 \n\n$HighChol\n\n    No    Yes \n146089 107591 \n\n$CholCheck\n\n    No    Yes \n  9470 244210 \n\n$Smoker\n\n    No    Yes \n141257 112423 \n\n$Stroke\n\n    No    Yes \n243388  10292 \n\n$HeartDiseaseorAttack\n\n    No    Yes \n229787  23893 \n\n$PhysActivity\n\n    No    Yes \n 61760 191920 \n\n$Fruits\n\n    No    Yes \n 92782 160898 \n\n$Veggies\n\n    No    Yes \n 47839 205841 \n\n$HvyAlcoholConsump\n\n    No    Yes \n239424  14256 \n\n$AnyHealthcare\n\n    No    Yes \n 12417 241263 \n\n$NoDocbcCost\n\n    No    Yes \n232326  21354 \n\n$GenHlth\n\nExcellent Very Good      Good      Fair      Poor \n    45299     89084     75646     31570     12081 \n\n$DiffWalk\n\n    No    Yes \n211005  42675 \n\n$Sex\n\nFemale   Male \n141974 111706 \n\n$Age\n\n18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79   80+ \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363 \n\n$Education\n\n    KG or No School          Elementary       Middle school         High school \n                174                4043                9478               62750 \n            College Professional Degree \n              69910              107325 \n\n$Income\n\n     &lt;10K $10k-$15k $15k-$20k $20k-$25k $25k-$35k $35k-$50k $50k-$75k     $75k+ \n     9811     11783     15994     20135     25883     36470     43219     90385 \n\n\n\nCheck the number of response variable\n\n\nunique(health_data$Diabetes_binary)\n\n[1] 0 1\n\n\n\nggplot(health_data, aes(x= Diabetes_binary, fill = Sex)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Diabetes status by Sex\")\n\n\n\n\n\n\n\n\n\ncont_table &lt;- table(health_data$Diabetes_binary, health_data$Sex)\n\ncont_table\n\n   \n    Female   Male\n  0 123563  94771\n  1  18411  16935\n\n\n\ndiab_count &lt;- health_data |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(count = n())\n\ndiab_count\n\n# A tibble: 2 × 2\n  Diabetes_binary  count\n            &lt;dbl&gt;  &lt;int&gt;\n1               0 218334\n2               1  35346\n\n\n\nWe can see that the response data is not balanced. Here is number of patient who have diabetes are less incomparison of number of patient who have diabetes.\nFind the diabetes Prevalence by Gender\n\n\nggplot(health_data, aes(x = Diabetes_binary, fill = Sex)) +\n  geom_bar(position = \"dodge\") +\n  geom_text(\n    stat = \"count\", \n    aes(label = ..count..), \n    position = position_dodge(width = 0.9), \n    vjust = -0.5\n  ) +\n  labs(\n    title = \"Diabetes Status by Gender\",\n    x = \"Diabetes Status (0 = No Diabetes, 1 = Diabetes)\",\n    y = \"Count\"\n  ) +\n  scale_fill_manual(values = c(\"Female\" = \"pink\", \"Male\" = \"blue\")) +\n  theme_minimal()\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\n\nIt is showing that number of females have more diabetes in comparison of male count\nJust checking is there any outlier in BMI column\n\n\nggplot(health_data, aes(x = \"\", y = BMI)) +\n  geom_boxplot(fill = \"orange\") +\n  labs(title = \"BMI Distribution\", x = \"\", y= \"BMI\")\n\n\n\n\n\n\n\n\n\nIt looks like there are some outlier in the BMI\n\n\nGeneral Health vs. Diabetes Status\n\nggplot(health_data, aes(x = GenHlth, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"General Health vs. Diabetes Status\", x = \"General Health\", y = \"Count\") +\n  scale_fill_manual(values = c(\"0\" = \"lightgreen\", \"1\" = \"red\"), name = \"Diabetes Status\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nLooks like according to General Health less people have diabetes.\n\n\n# Summarize the counts for Diabetes_binary by Sex\ndiab_count &lt;- health_data %&gt;%\n  group_by(Sex) %&gt;%\n  summarize(count = n())\n\n# Plot using the aggregated data\nggplot(diab_count, aes(x = Sex, y = count, fill = Sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \"Count of Diabetes Cases by Sex\",\n    x = \"Sex\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nSome quick summary stats, We are going to focus on modeling the Diabetes_binary\n\n\n# do some correlation on the numerical data \nhealth_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n                Diabetes_binary   BMI MentHlth PhysHlth\nDiabetes_binary           1.000 0.217    0.069    0.171\nBMI                       0.217 1.000    0.085    0.121\nMentHlth                  0.069 0.085    1.000    0.354\nPhysHlth                  0.171 0.121    0.354    1.000"
  },
  {
    "objectID": "EDA_p.html#link-to-navigate-to-the-modeling.qmd",
    "href": "EDA_p.html#link-to-navigate-to-the-modeling.qmd",
    "title": "EDA",
    "section": "Link to navigate to the Modeling.qmd",
    "text": "Link to navigate to the Modeling.qmd\n[click here for the Modeling Page] (http://localhost:7471)\nhttp://localhost:5248"
  },
  {
    "objectID": "Modelling.html",
    "href": "Modelling.html",
    "title": "Modelling",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Modelling.html#quarto",
    "href": "Modelling.html#quarto",
    "title": "Modelling",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Modelling.html#running-code",
    "href": "Modelling.html#running-code",
    "title": "Modelling",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "Modelling.html#reading-data",
    "href": "Modelling.html#reading-data",
    "title": "Modelling",
    "section": "Reading Data",
    "text": "Reading Data\nImport the libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\n\n\nhealth_data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(health_data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\n\nhealth_data &lt;- health_data |&gt;\n  mutate(HighBP = factor(HighBP, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         HighChol = factor(HighChol, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         CholCheck = factor(CholCheck, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Smoker = factor(Smoker, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Stroke = factor(Stroke, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0,1), labels = c(\"No\",\"Yes\")),\n         PhysActivity = factor(PhysActivity, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Fruits = factor(Fruits, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Veggies = factor(Veggies, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n         AnyHealthcare = factor(AnyHealthcare, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         NoDocbcCost = factor(NoDocbcCost, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         GenHlth = factor(GenHlth, levels = c(1:5), labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n         DiffWalk = factor(DiffWalk, levels = c(0,1), labels = c(\"No\", \"Yes\")),\n         Sex = factor(Sex, levels = c(0,1), labels = c(\"Female\", \"Male\")),\n         Age = factor(Age, levels = c(1:13), labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\")),\n         Education = factor(Education, levels = c(1:6), labels = c(\"KG or No School\", \"Elementary\", \"Middle school\", \"High school\", \"College\",\"Professional Degree\")),\n         Income = factor(Income, levels = c(1:8), labels = c(\"&lt;10K\", \"$10k-$15k\", \"$15k-$20k\", \"$20k-$25k\", \"$25k-$35k\", \"$35k-$50k\", \"$50k-$75k\", \"$75k+\"))\n         )\n\nhealth_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1               0 Yes    Yes      Yes          40 Yes    No    \n 2               0 No     No       No           25 Yes    No    \n 3               0 Yes    Yes      Yes          28 No     No    \n 4               0 Yes    No       Yes          27 No     No    \n 5               0 Yes    Yes      Yes          24 No     No    \n 6               0 Yes    Yes      Yes          25 Yes    No    \n 7               0 Yes    No       Yes          30 Yes    No    \n 8               0 Yes    Yes      Yes          25 Yes    No    \n 9               1 Yes    Yes      Yes          30 Yes    No    \n10               0 No     No       Yes          24 No     No    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n\n\n\nMake a model for diabetes data. Split the data into 70(training) and 30(testing) percent.\nOn the training set, create a 5 fold CV split\n\n\nset.seed(37)\nhealth_data &lt;- health_data |&gt; mutate(Diabetes_binary = factor(Diabetes_binary))\ndiabetes_split &lt;- initial_split(health_data, prop = 0.7, strata = Diabetes_binary)\ndiabetes_train &lt;- training(diabetes_split)\ndiabetes_test &lt;- testing(diabetes_split)\n\ndiabetes_CV_folds &lt;- vfold_cv(diabetes_train, 5)\n\n\n### Fitting Logistic Regression Models\nFirst of all i have to set up our recipes for the data, standardizing the BMI numeric variable\nfor the 1st recipe:\n\nModel 1: BMI and Smoker\nModel 2: BMI, Smoker, HighBP, HearthDiseaserorAttack, PhysActivity, Sex\nModel 3: All the predictors\n\n\n# LR1_receipe &lt;- recipe(Diabetes_binary ~  BMI + Smoker,\n#                       data = health_data) |&gt;\n#   step_normalize(BMI)\n\n\nLR2_recipe &lt;- recipe(Diabetes_binary ~ BMI + Smoker + HighBP + HeartDiseaseorAttack + PhysActivity + Sex,\n                     data = health_data) |&gt;\n  step_normalize(all_numeric(), -Diabetes_binary)\n\n\n# LR3_recipe &lt;- recipe(Diabetes_binary ~ ., data = health_data) |&gt;\n#   step_normalize(all_numeric(), -Diabetes_binary)\n\n\nLR2_recipe |&gt;\n  prep(diabetes_train) |&gt;\n  bake(diabetes_train) |&gt;\n  colnames()\n\n[1] \"BMI\"                  \"Smoker\"               \"HighBP\"              \n[4] \"HeartDiseaseorAttack\" \"PhysActivity\"         \"Sex\"                 \n[7] \"Diabetes_binary\"     \n\n\n\n# LR3_recipe |&gt;\n#   prep(diabetes_train) |&gt;\n#   bake(diabetes_train) |&gt;\n#   colnames()\n\n\nClassification Tree\n\n\nDecision Tree\nModel Specification\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 20,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\nCreate our Workflow\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(LR2_recipe) |&gt;\n  add_model(tree_mod)\n\nFit the model with tune_grid() and grid_regular()\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = c(10,5))\n\n\ntree_fits &lt;- tree_wkf |&gt;\n  tune_grid(resamples = diabetes_CV_folds,\n            grid = tree_grid,\n            metrics = metric_set(accuracy, mn_log_loss)\n  )\n\ntree_fits\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits                 id    .metrics           .notes          \n  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;             &lt;list&gt;          \n1 &lt;split [142060/35515]&gt; Fold1 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [142060/35515]&gt; Fold2 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [142060/35515]&gt; Fold4 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [142060/35515]&gt; Fold5 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n\nLet see which is the best accuracy\n\nbest_tree &lt;- select_best(tree_fits, metric = \"mn_log_loss\")\n\nFinalize the workflow and fit the model\n\nfinal_tree &lt;- finalize_workflow(tree_wkf, best_tree) |&gt;\n  fit(data = diabetes_train)\n\nEvaluate the model on the test set # TRy\n\ntree_pred &lt;- predict(final_tree, diabetes_test, type = \"prob\") |&gt;\n  bind_cols(diabetes_test |&gt;\n              select(Diabetes_binary))\n\nlog-loss on test data\n\nprint(tree_pred)\n\n# A tibble: 76,105 × 3\n   .pred_0 .pred_1 Diabetes_binary\n     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;          \n 1   0.812  0.188  0              \n 2   0.812  0.188  1              \n 3   0.963  0.0371 1              \n 4   0.812  0.188  0              \n 5   0.963  0.0371 0              \n 6   0.812  0.188  0              \n 7   0.425  0.575  1              \n 8   0.916  0.0843 0              \n 9   0.963  0.0371 0              \n10   0.963  0.0371 0              \n# ℹ 76,095 more rows\n\ntree_log_loss &lt;- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1)\nprint(tree_log_loss)\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 mn_log_loss binary          2.14"
  },
  {
    "objectID": "Modelling.html#fitting-random-forest",
    "href": "Modelling.html#fitting-random-forest",
    "title": "Modelling",
    "section": "Fitting Random Forest",
    "text": "Fitting Random Forest\n\nrf_spec &lt;- rand_forest(mtry = tune(),\n                       trees = 1000, \n                       min_n = tune()) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"classification\")\n\nCreate our workflow\n\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(LR2_recipe) |&gt;\n  add_model(rf_spec)\n\nfit model with tune_grid() and tune_regular()\n\nrf_fit &lt;- rf_wkf |&gt;\n  tune_grid(resamples = diabetes_CV_folds,\n            grid = 12,\n            metrics = metric_set(accuracy, mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nCollect and view metrics\n\n# rf_fit |&gt;\n#   collect_metrics() |&gt;\n#   filter(.metric == \"mn_log_loss\") |&gt;\n#   arrange(mean)\n\n#print(rf_metrics)\n\nLet’s see which tuning parameters is best\n\nrf_best_params &lt;- select_best(rf_fit, metric = \"mn_log_loss\")\nrf_best_params\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     3    32 Preprocessor1_Model05\n\n\nFinalize the workflow with the best parameters\n\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\nFit the finalize model and evaluate on the test set\n\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(diabetes_split, metrics = metric_set(accuracy, mn_log_loss))\n\nCollect metrics for the final model\n\nrf_final_metrics &lt;- rf_final_fit |&gt;\n  collect_metrics()\n\nrf_final_metrics\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.862 Preprocessor1_Model1\n2 mn_log_loss binary         0.345 Preprocessor1_Model1\n\n\n\n\n\nDecision Tree Test set performance\n\n\n# Get predicted probabilities\ntree_final_predictions &lt;- final_tree |&gt;\n   predict(diabetes_test, type = \"prob\") |&gt;\n   bind_cols(diabetes_test |&gt; select(Diabetes_binary))\n\n# Convert predicted probabilities to class labels (threshold at 0.5)\n tree_final_predictions &lt;- tree_final_predictions |&gt;\n   mutate(.pred_class = ifelse(.pred_1 &gt; 0.5, \"1\", \"0\"))\n\n# Convert the class labels into factors for accuracy calculation\n tree_final_predictions &lt;- tree_final_predictions |&gt;\n   mutate(.pred_class = factor(.pred_class, levels = c(\"0\", \"1\")))\n\n# Now calculate metrics\n tree_final_metrics &lt;- yardstick::metrics(\n   tree_final_predictions,   truth = Diabetes_binary,\n   estimate = .pred_class\n\n)\n\n# View metrics\ntree_final_metrics\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.861 \n2 kap      binary        0.0654\n\n\n\n# # Evaluation of Decision Tree\n# tree_pred &lt;- predict(final_tree, diabetes_test, type = \"prob\") |&gt;\n#   bind_cols(diabetes_test %&gt;% select(Diabetes_binary))\n# \n#tree_log_loss &lt;- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1)\n# \n# # Evaluation of Random Forest\n# rf_pred &lt;- predict(rf_final_fit, diabetes_test, type = \"prob\") |&gt;\n#   bind_cols(diabetes_test %&gt;% select(Diabetes_binary))\n# \n# # Log loss for Random Forest\n# rf_log_loss &lt;- mn_log_loss(rf_pred, truth = Diabetes_binary, .pred_1)\n# \n\n\n# Calculate Log-Loss for Decision Tree\ntree_log_loss &lt;- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1)\n\n# Extract the finalized workflow from last_fit() \nrf_workflow_extracted &lt;- extract_workflow(rf_final_fit)\n\n# Predict probabilities on the test set\nrf_pred &lt;- predict(rf_workflow_extracted, diabetes_test, type = \"prob\") |&gt;\n  bind_cols(diabetes_test %&gt;% select(Diabetes_binary))\n\n# Calculate Log-Loss for the Random Forest Model\nrf_log_loss &lt;- mn_log_loss(rf_pred, truth = Diabetes_binary, .pred_1)\n\n# Convert predicted probabilities to class labels for accuracy evaluation\nrf_pred &lt;- rf_pred |&gt;\n  mutate(.pred_class = ifelse(.pred_1 &gt; 0.5, \"1\", \"0\")) |&gt;\n  mutate(.pred_class = factor(.pred_class, levels = c(\"0\", \"1\")))\n\n# Evaluate metrics (accuracy, etc.)\nrf_metrics &lt;- rf_pred |&gt;\n  yardstick::metrics(truth = Diabetes_binary, estimate = .pred_class)\n\n# Print metrics\nprint(rf_metrics)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.862 \n2 kap      binary        0.0682\n\n\n\n# Compare models}\n# model_comparison &lt;- tibble(\n#   Model = c(\"Decision Tree\", \"Random Forest\"),\n#   Log_Loss = c(tree_log_loss, rf_log_loss)\n# )\n# \n# print(model_comparison)\n\nprint(tree_log_loss)\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 mn_log_loss binary          2.14\n\nprint(rf_log_loss)\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 mn_log_loss binary          2.19\n\n\n\nRandom Forest Test Set performance\n\n\nrf_final_metrics &lt;- rf_final_fit |&gt;\n  collect_metrics()\n\nrf_final_metrics\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.862 Preprocessor1_Model1\n2 mn_log_loss binary         0.345 Preprocessor1_Model1\n\n\n\n\nCompare Performance\n\n# Combine Metrics into a DataFrame for Comparison\nmodel_comparison &lt;- tibble(\n  Model = c(\"Decision Tree\", \"Random Forest\"),\n  Accuracy = c(tree_final_metrics |&gt; filter(.metric == \"accuracy\") |&gt; pull(.estimate),\n               rf_final_metrics |&gt; filter(.metric == \"accuracy\") |&gt; pull(.estimate)),\n  Log_Loss = c(tree_final_metrics |&gt; filter(.metric ==\"mn_log_loss\") |&gt; pull(.estimate),\n               rf_final_metrics |&gt; filter(.metric ==\"mn_log_loss\") |&gt; pull(.estimate))\n)\n\nprint(model_comparison)\n\n# A tibble: 2 × 3\n  Model         Accuracy Log_Loss\n  &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n1 Decision Tree    0.861    0.345\n2 Random Forest    0.862    0.345\n\n\n\n# Declare winner based on log-loss\n# Calculate log-loss\ntree_log_loss &lt;- mn_log_loss(tree_pred, truth = Diabetes_binary, .pred_1) %&gt;% pull(.estimate)\nrf_log_loss &lt;- mn_log_loss(rf_pred, truth = Diabetes_binary, .pred_1) %&gt;% pull(.estimate)\nprint(tree_log_loss)\n\n[1] 2.138608\n\nprint(rf_log_loss)\n\n[1] 2.186594\n\n# Declare winner\nif (tree_log_loss &lt; rf_log_loss) {\n  winner &lt;- \"Decision Tree\"\n} else {\n  winner &lt;- \"Random Forest\"\n}\n\n# Print the winner\ncat(\"The best model is:\", winner)\n\nThe best model is: Decision Tree\n\n\nPlot the variable importance\n\n# bag_final_model &lt;- extract_fit_engine(rf_final_fit)\n# bag_final_model$imp |&gt;\n#   mutate(term = factor(term, levels = term)) |&gt; \n#   ggplot(aes(x = term, y = value)) + geom_bar(stat =\"identity\") +\n#   coord_flip()\n\n\n\nSave the file for api\n\n# # save the training data set\n# saveRDS(diabetes_train, file = \"data/diabetes_train.rds\")\n# \n# # save the random forest tree model\n# saveRDS(rf_final_fit, file = \"data/final_rf_model.rds\")\n# \n# #save the comparison metrics\n# saveRDS(model_comparison, file = \"data/model_comparison.rds\")"
  }
]